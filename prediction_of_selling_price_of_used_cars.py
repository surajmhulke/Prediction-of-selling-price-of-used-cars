# -*- coding: utf-8 -*-
"""Prediction of selling price of used cars.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ij2cUWIrg5g_phEEvqoy4maTZ6QjOKWX
"""

import numpy as np
import pandas as pd
#Visualization
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score

# 1. Problem Statement
#To predict price of cars using various features

# 2. Data Gathering
df = pd.read_csv("/content/autos_dataset.csv")
df

df.head() # head() function is generally use for to print first 5 rows bydefault

df.head().T # after use of T after head() function, Columns goes to rows place and Rows goes to Columns place

# 3. Exploratory Data Analysis (EDA) :

df.info()

df.isna().sum() # Checking there is avl. of any NaN values

"""Check all the columns one by one, fill the NaN values , Convert "object" Data Types into "int" or "float" bcz during
Model Training and Model valuation Calculation , it is must requirement of integers"""

# 3.1 Symboling

df["symboling"]

# 3.2 normalized-losses

df["normalized-losses"]

"""In the return output we see question marks and its data type is "object" , so this ? qustion mark indicate it is NaN Value.
It is necessary to convert this ? question marks to NaN standard format.
Because it is generate some confusion because its data type is "object" and at isna().sum() function there is also shows
there is not available of NaN values.
So we replace ? Question mark into NaN Value."""

df.replace({"?":np.nan},inplace=True) # By using replace function we replace all question mark with NaN Values

df.isna().sum() # After replace of ? question mark we find summary of availabiliy of NaN Values.

df.info()

df["normalized-losses"] = df["normalized-losses"].astype(float) # "normalized-losses" this column in "object" data type
 # So we converted into "float" data type

df["normalized-losses"].mean()

df["normalized-losses"].median()

"""We check both Mean and Median for "normalized-losses" column but Mean value is slighter greater than Median.
This is because of availablity of some Outliers.
So we use Median to fill the NaN Values."""

df["normalized-losses"] = df["normalized-losses"].fillna(df["normalized-losses"].median()).astype(int)
# we fill the NaN Values by Median of "normalized-losses" column and converted into "int" data type

df["normalized-losses"]

df.info() # By doing Type Casting we convert "object" into "int" data type and
 # We fill the NaN Values by Median of "normalized-losses" column
# Like wise that we process all Columns( Fill NaN Values and Converted into "int" or "float")

# 3.3 make
df["make"]

df["make"].nunique() # We find out how many type of unique values availale in " make " column

df["make"].value_counts() # We find out how many type of unique values availale and its Count

#3.4 fuel-type

df["fuel-type"].value_counts()

df["fuel-type"].replace({'gas' : 0 , 'diesel' : 1}, inplace = True)

df["fuel-type"].value_counts()

df.info()

# 3.5 aspiration

df['aspiration'].value_counts()

df['aspiration'].replace({'std' : 0 , 'turbo' : 1}, inplace = True)

df['aspiration'].value_counts()

# 3.6 num-of-doors

df['num-of-doors'].value_counts()

df['num-of-doors'].replace({'four' : 4 , 'two' : 2}, inplace = True)
df['num-of-doors'].value_counts()

df['num-of-doors'].mean()

df['num-of-doors'].median()

df['num-of-doors'].mode()[0]

df['num-of-doors'].fillna(df['num-of-doors'].median() , inplace = True)

##3.7 body-style

df['body-style'].value_counts()

df.T

df = pd.get_dummies(df,columns = ['body-style'])
df

#3.8 drive-wheels

df['drive-wheels'].value_counts()

df['drive-wheels'].replace({"fwd" : 0 , "rwd" : 1 , "4wd" : 2}, inplace=True)
df['drive-wheels'].value_counts()

# 3.9 engine-location#

df['engine-location'].value_counts()

df['engine-location'].replace({"front" : 0 , "rear" : 1 }, inplace=True)
df['engine-location'].value_counts()

# 3.14 engine-type
df['engine-type'].value_counts()

df = pd.get_dummies(df, columns=['engine-type'])
df

df.info()

# 3.15 num-of-cylinders

df['num-of-cylinders'].value_counts()

df['num-of-cylinders'].replace({'four' : 4 , 'six' : 6 , 'five' : 5 , 'eight' : 8 ,
 'two' : 2, 'three' : 3,'twelve' : 12}, inplace = True)
df['num-of-cylinders'].value_counts()

df

# 3.17 fuel-system

df = pd.get_dummies(df, columns = ['fuel-system'] )
df

df.T

# 3.18 bore

df["bore"] = df["bore"].fillna(df["bore"].median()).astype(float)
df['stroke'] = df["stroke"].fillna(df["bore"].median()).astype(float)
df['horsepower'] = df["horsepower"].fillna(df["bore"].median()).astype(float)
df['peak-rpm'] = df['peak-rpm'].fillna(df['peak-rpm'].median()).astype(float)
df['price'] = df['price'].fillna(df['price'].median()).astype(float)

df.info()

# 4 . Fetaure Selection

df.corr()

# 5. Train Test Split

df = df.select_dtypes(exclude = object) # we drop column having Data type is " object "

df.info() # We fill all NaN Values & Only int and float data type available....Now we ready for further operations

x = df.drop("price",axis = 1) # It returns all Independent Variables
y = df["price"] # It returns all Dependent Variables

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=34)
x_train

x_train.shape

# 6. Model Training

model = LinearRegression()
model.fit(x_train,y_train)

# 7. Model Evaluation
 y_pred_test = model.predict(x_test) # To find Predicted Values

#Testing data evalution
y_pred = model.predict(x_test)
y_pred[20:25]

y_pred_test[20:25] # Predicted values

y_test[20:25] # actual values

# 8. Testing Data Evalution

mse = mean_squared_error(y_test,y_pred_test)
print("MSE is:",mse)
rmse = np.sqrt(mse)
print("RMSE:",rmse)
mae = mean_absolute_error(y_test,y_pred_test)
print("MAE is:",mae)
r2 = r2_score(y_test,y_pred_test)
print("r2 score is :",r2)

# 9. Training Data Evalution
y_pred_train = model.predict(x_train)
mse = mean_squared_error(y_train,y_pred_train)
print("MSE is:",mse)
rmse = np.sqrt(mse)
print("RMSE:",rmse)
mae = mean_absolute_error(y_train,y_pred_train)
print("MAE is:",mae)
r2 = r2_score(y_train,y_pred_train)
print("r2 score is :",r2)

